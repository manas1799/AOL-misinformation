{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf85bea0-68bf-4405-96ec-37579b2e9587",
      "metadata": {
        "id": "cf85bea0-68bf-4405-96ec-37579b2e9587"
      },
      "source": [
        "# Homework and bakeoff: Few-shot OpenQA with DSPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a28e9bf5-7956-4c63-9129-7f2cbc468075",
      "metadata": {
        "id": "a28e9bf5-7956-4c63-9129-7f2cbc468075"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Christopher Potts and Omar Khattab\"\n",
        "__version__ = \"CS224u, Stanford, Fall 2024\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b5d964-a45c-496a-bb46-8f31d7b2d591",
      "metadata": {
        "id": "b7b5d964-a45c-496a-bb46-8f31d7b2d591"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/master/hw_openqa.ipynb)\n",
        "\n",
        "If Colab is opened with this badge, please **save a copy to drive** (from the File menu) before running the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8570fc5-2ac0-4c0e-b350-71990937ebd8",
      "metadata": {
        "id": "d8570fc5-2ac0-4c0e-b350-71990937ebd8"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4da2d82-8c54-4d41-a59d-891f83f85f6e",
      "metadata": {
        "id": "f4da2d82-8c54-4d41-a59d-891f83f85f6e"
      },
      "source": [
        "The goal of this homework is to explore retrieval-augmented in-context learning. This is an exciting area that brings together a number of recent task ideas and modeling innovations. We will use the [DSPy programming library](http://dspy.ai) to build systems in this new mode.\n",
        "\n",
        "Our core task is __open-domain question answering (OpenQA)__. In this task, all that is given by the dataset is a question text, and the task is to answer that question. By contrast, in many modern QA tasks, the dataset provides a text and a gold passage, usually with a firm guarantee that the answer will be a substring of the passage.\n",
        "\n",
        "OpenQA is substantially harder than standard QA. The usual strategy is to use a _retriever_ to find passages in a large collection of texts and train a _reader_ to find answers in those passages. This means we have no guarantee that the retrieved passage will contain the answer we need. If we don't retrieve a passage containing the answer, our reader has no hope of succeeding. Although this is challenging, it is much more realistic and widely applicable than standard QA. After all, with the right retriever, an OpenQA system could be deployed over the entire Web.\n",
        "\n",
        "The task posed by this homework is harder even than OpenQA. We are calling this task __few-shot OpenQA__. The defining feature of this task is that the reader is simply a frozen, general purpose language model. It accepts string inputs (prompts) and produces text in response. It is not trained to answer questions per se, and nothing about its structure ensures that it will respond with a substring of the prompt corresponding to anything like an answer.\n",
        "\n",
        "__Few-shot QA__ (but not OpenQA!) is explored in the famous GPT-3 paper ([Brown et al. 2020](https://arxiv.org/abs/2005.14165)). The authors are able to get traction on the problem using GPT-3, an incredible finding. Our task here – __few-shot OpenQA__ – pushes this even further by retrieving passages to use in the prompt rather than assuming that the gold passage can be used in the prompt. If we can make this work, then it should be a major step towards flexibly and easily deploying QA technologies in new domains.\n",
        "\n",
        "In summary:\n",
        "\n",
        "| Task             | Passage given | Task-specific reader training |Task-specific retriever training  |\n",
        "|-----------------:|:-------------:|:-----------------------------:|:--------------------------------:|\n",
        "| QA               | yes           | yes                           | n/a                              |\n",
        "| OpenQA           | no            | yes                           | maybe                            |\n",
        "| Few-shot QA      | yes           | no                            | n/a                              |\n",
        "| Few-shot OpenQA  | no            | no                            | maybe                            |\n",
        "\n",
        "Just to repeat: your mission is to explore the final line in this table. The core notebook and assignment don't address the issue of training the retriever in a task-specific way, but this is something you could pursue for a final project; [the ColBERT codebase](https://github.com/stanford-futuredata/ColBERT) makes easy.\n",
        "\n",
        "It is a requirement of the bake-off that a general-purpose language model be used. In particular, trained QA systems cannot be used at all, and no fine-tuning is allowed either. See the original system question at the bottom of this message for guidance on which models are allowed.\n",
        "\n",
        "Note: the models we are working with here are _big_. This poses a challenge that is increasingly common in NLP: you have to pay one way or another. You can pay to use the GPT-3 API, or you can pay to use a local model on a heavy-duty cluster computer, or you can pay with time by using a local model on a more modest computer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cd32bb4-067f-4cd6-943f-3e5574400beb",
      "metadata": {
        "id": "0cd32bb4-067f-4cd6-943f-3e5574400beb"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149bcb0f-bc76-4277-a359-742d6dcee063",
      "metadata": {
        "id": "149bcb0f-bc76-4277-a359-742d6dcee063"
      },
      "source": [
        "We have sought to make this notebook self-contained and easy to use on a personal computer, on Google Colab, and in Sagemaker Studio. For personal computer use, we assume you have already done everything in [setup.ipynb](setup.ipynb]). For cloud usage, the next few code blocks should handle all set-up steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62b983bb-a20a-4c2a-9eee-9c553dd8c070",
      "metadata": {
        "id": "62b983bb-a20a-4c2a-9eee-9c553dd8c070",
        "outputId": "b225129b-12d0-481b-d18a-4839a79091de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs224u'...\n",
            "remote: Enumerating objects: 2409, done.\u001b[K\n",
            "remote: Counting objects: 100% (232/232), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 2409 (delta 150), reused 127 (delta 119), pack-reused 2177 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2409/2409), 41.76 MiB | 36.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1467/1467), done.\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 2)) (1.14.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.7 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 5)) (3.9.1)\n",
            "Requirement already satisfied: pytest>=7.1 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 6)) (8.3.5)\n",
            "Collecting jupyter>=1.0.0 (from -r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: transformers>=4.37 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 16)) (4.49.0)\n",
            "Collecting datasets>=2.14.6 (from -r cs224u/requirements.txt (line 17))\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: spacy>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from -r cs224u/requirements.txt (line 18)) (3.8.4)\n",
            "Collecting colbert-ai>=0.2.20 (from -r cs224u/requirements.txt (line 19))\n",
            "  Downloading colbert_ai-0.2.21-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dspy-ai==2.4.13 (from -r cs224u/requirements.txt (line 21))\n",
            "  Downloading dspy_ai-2.4.13-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting python-dotenv (from -r cs224u/requirements.txt (line 22))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting wget (from -r cs224u/requirements.txt (line 23))\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openai==1.61.1 (from -r cs224u/requirements.txt (line 24))\n",
            "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting backoff (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (1.4.2)\n",
            "Collecting optuna (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.10.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.32.3)\n",
            "Collecting structlog (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading structlog-25.2.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (4.67.1)\n",
            "Collecting ujson (from dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.61.1->-r cs224u/requirements.txt (line 24)) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->-r cs224u/requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.7->-r cs224u/requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.1->-r cs224u/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->-r cs224u/requirements.txt (line 8)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5->-r cs224u/requirements.txt (line 8)) (2025.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (0.29.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.37->-r cs224u/requirements.txt (line 16)) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.14.6->-r cs224u/requirements.txt (line 17))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (3.11.14)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.15.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.5.0)\n",
            "Collecting bitarray (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19))\n",
            "  Downloading bitarray-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (3.1.0)\n",
            "Collecting git-python (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19))\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
            "Collecting ninja (from colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19))\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (3.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r cs224u/requirements.txt (line 17)) (1.18.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.61.1->-r cs224u/requirements.txt (line 24)) (0.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.0->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.0->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r cs224u/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.3.0)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (7.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.2)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from git-python->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (3.1.44)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.18.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.2.0)\n",
            "Collecting alembic>=1.5.0 (from optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (2.0.39)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (1.1.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.3.6)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (21.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.21.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (1.17.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->dspy-ai==2.4.13->-r cs224u/requirements.txt (line 21)) (3.1.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->git-python->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai>=0.2.20->-r cs224u/requirements.txt (line 19)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.8.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.7.2->-r cs224u/requirements.txt (line 18)) (0.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7)) (24.11.1)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r cs224u/requirements.txt (line 7))\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading dspy_ai-2.4.13-py3-none-any.whl (280 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colbert_ai-0.2.21-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.1/116.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bitarray-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-25.2.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=ea02d9d9cafecd260f8b5786aaf748635fb7346b67674177e4b486814050f195\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, bitarray, xxhash, uri-template, ujson, types-python-dateutil, structlog, rfc3986-validator, rfc3339-validator, python-json-logger, python-dotenv, overrides, ninja, json5, jedi, fsspec, fqdn, dill, colorlog, backoff, async-lru, multiprocess, jupyter-server-terminals, jupyter-client, arrow, alembic, optuna, openai, isoduration, git-python, datasets, jupyter-events, dspy-ai, colbert-ai, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.66.3\n",
            "    Uninstalling openai-1.66.3:\n",
            "      Successfully uninstalled openai-1.66.3\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.15.1 arrow-1.3.0 async-lru-2.0.5 backoff-2.2.1 bitarray-3.2.0 colbert-ai-0.2.21 colorlog-6.9.0 datasets-3.4.1 dill-0.3.8 dspy-ai-2.4.13 fqdn-1.5.1 fsspec-2024.12.0 git-python-1.0.3 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.6 jupyterlab-server-2.27.3 multiprocess-0.70.16 ninja-1.11.1.4 openai-1.61.1 optuna-4.2.1 overrides-7.7.0 python-dotenv-1.0.1 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 structlog-25.2.0 types-python-dateutil-2.9.0.20241206 ujson-5.10.0 uri-template-1.3.0 wget-3.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # This library is our indicator that the required installs\n",
        "    # need to be done.\n",
        "    import datasets\n",
        "    root_path = '.'\n",
        "except ModuleNotFoundError:\n",
        "    !git clone https://github.com/cgpotts/cs224u/\n",
        "    !pip install -r cs224u/requirements.txt\n",
        "    root_path = 'dspy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1afb7791-92a3-474d-8c2f-807dc2441413",
      "metadata": {
        "id": "1afb7791-92a3-474d-8c2f-807dc2441413"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "import dspy\n",
        "import warnings\n",
        "\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad2651d-9868-45bf-81df-afafa832896a",
      "metadata": {
        "id": "6ad2651d-9868-45bf-81df-afafa832896a"
      },
      "source": [
        "### OpenAI set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a04cb488-cd40-4f9d-b884-8ff83b012042",
      "metadata": {
        "id": "a04cb488-cd40-4f9d-b884-8ff83b012042"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c9da704b-d27b-480a-93b5-e16cf7c51803",
      "metadata": {
        "id": "c9da704b-d27b-480a-93b5-e16cf7c51803"
      },
      "outputs": [],
      "source": [
        "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
        "\n",
        "\n",
        "# keep the API keys in a `.env` file in the local root directory\n",
        "load_dotenv()\n",
        "\n",
        "openai_key = os.getenv('OPENAI_API_KEY')  # use the .env file as it is a good practice to keep keys outside of one's code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4465db5-4572-457e-b053-10f0185536fe",
      "metadata": {
        "id": "c4465db5-4572-457e-b053-10f0185536fe"
      },
      "source": [
        "### ColBERT set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63747138-ae9c-4fc6-b508-0ad411fd58ac",
      "metadata": {
        "id": "63747138-ae9c-4fc6-b508-0ad411fd58ac"
      },
      "source": [
        "#### Pretrained ColBERT parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf06f38-3dd6-4171-8b72-f5703df140d8",
      "metadata": {
        "id": "caf06f38-3dd6-4171-8b72-f5703df140d8"
      },
      "source": [
        "For this set-up phase, we first download pretrained ColBERT parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4925831c-f4d2-4b6b-87ed-145125c8f668",
      "metadata": {
        "id": "4925831c-f4d2-4b6b-87ed-145125c8f668",
        "outputId": "44b381f4-38db-467a-9fa1-6e45d9972117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-23 20:32:09--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405924985 (387M) [application/octet-stream]\n",
            "Saving to: ‘data/openqa/colbertv2.0.tar.gz’\n",
            "\n",
            "colbertv2.0.tar.gz  100%[===================>] 387.12M  1.54MB/s    in 1m 54s  \n",
            "\n",
            "2025-03-23 20:34:08 (3.41 MB/s) - ‘data/openqa/colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
            "\n",
            "colbertv2.0/\n",
            "colbertv2.0/artifact.metadata\n",
            "colbertv2.0/vocab.txt\n",
            "colbertv2.0/tokenizer.json\n",
            "colbertv2.0/special_tokens_map.json\n",
            "colbertv2.0/tokenizer_config.json\n",
            "colbertv2.0/config.json\n",
            "colbertv2.0/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"colbertv2.0.tar.gz\")):\n",
        "    !mkdir -p data/openqa\n",
        "    # ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
        "    !wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P data/openqa/\n",
        "    !tar -xvzf data/openqa/colbertv2.0.tar.gz -C data/openqa/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a89bd6c-5497-4808-b2cf-9e15d9c37104",
      "metadata": {
        "id": "9a89bd6c-5497-4808-b2cf-9e15d9c37104"
      },
      "source": [
        "If something went wrong with the above, you can just download the file https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz, unarchive it, and move the resulting `colbertv2.0` directory into the `data/openqa` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf501ee-290b-4007-b04d-c175c3124806",
      "metadata": {
        "id": "4bf501ee-290b-4007-b04d-c175c3124806"
      },
      "source": [
        "#### Prebuilt ColBERT index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e330d4c-3d9f-4182-9c40-37010a5e5afd",
      "metadata": {
        "id": "8e330d4c-3d9f-4182-9c40-37010a5e5afd"
      },
      "source": [
        "Then we download a prebuilt index that covers the domain of our task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7d4bc73b-6936-44e2-bc80-7aca800abd75",
      "metadata": {
        "id": "7d4bc73b-6936-44e2-bc80-7aca800abd75"
      },
      "outputs": [],
      "source": [
        "index_home = os.path.join(\"experiments\", \"notebook\", \"indexes\", \"cs224u.collection.2bits\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/drive/folders/1h3jO9bWrlikm1shX80F-HUpqCiGzSUI_\n"
      ],
      "metadata": {
        "id": "xjb_n-Md-rKe"
      },
      "id": "xjb_n-Md-rKe"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index_home = 'experiments/notebook/indexes/cs224u.collection.2bits'\n",
        "os.makedirs('experiments/notebook/indexes', exist_ok=True)\n",
        "\n",
        "if not os.path.exists(index_home):\n",
        "    file_id = '1AbcDefGHIjklmnopQRstUvWXyz'  # 🔄 Replace with your actual file ID\n",
        "    output_file = 'experiments/notebook/indexes/cs224u.collection.2bits.tgz'\n",
        "\n",
        "    # Download from Google Drive\n",
        "    !gdown https://drive.google.com/uc?id={file_id} -O {output_file}\n",
        "\n",
        "    # Extract the tar.gz\n",
        "    !tar -xvzf {output_file} -C experiments/notebook/indexes"
      ],
      "metadata": {
        "id": "54i8HNfF-AyR"
      },
      "id": "54i8HNfF-AyR",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_home"
      ],
      "metadata": {
        "id": "EWfqUnfC_MFJ",
        "outputId": "0539745d-6654-406b-b75d-5d4828a7482a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "EWfqUnfC_MFJ",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'experiments/notebook/indexes/cs224u.collection.2bits'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "11d8dd51-d0d9-4d72-ae77-f00f6151889d",
      "metadata": {
        "id": "11d8dd51-d0d9-4d72-ae77-f00f6151889d"
      },
      "outputs": [],
      "source": [
        "# if not os.path.exists(index_home):\n",
        "#     !wget https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz -P experiments/notebook/indexes\n",
        "#     !tar -xvzf experiments/notebook/indexes/cs224u.collection.2bits.tgz -C experiments/notebook/indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a2443e3-efe6-444d-98bd-63fa2634d8ff",
      "metadata": {
        "id": "2a2443e3-efe6-444d-98bd-63fa2634d8ff"
      },
      "source": [
        "If something went wrong with the above, download the file https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz, unarchive it, and move the resulting `cs224u.collection.2bits` directory into the `experiments/notebook/indexes` directory (which you will probably need to create)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd3e9ff-c3d4-4a02-acfa-0d9183bce133",
      "metadata": {
        "id": "3bd3e9ff-c3d4-4a02-acfa-0d9183bce133"
      },
      "source": [
        "#### ColBERT server"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fde4ad-a0e2-49a2-b3ec-446c5cb95a95",
      "metadata": {
        "id": "90fde4ad-a0e2-49a2-b3ec-446c5cb95a95"
      },
      "source": [
        "The final step for ColBERT is to create a local retriever for use with DSPy. The preferred method for doing this is with a seperate server.\n",
        "\n",
        "__Local usage__: If you are working with this notebook locally and a having a CUDA based device, make sure you have the [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) installed to be able to serve it on GPU. Otherwise you would need to run it on CPU. The next steps are for GPU usage.\n",
        "Open a new terminal window, navigate to the same directory as this notebook, and enter the following code:\n",
        "\n",
        "```\n",
        "conda activate nlu\n",
        "git clone https://github.com/stanford-futuredata/ColBERT/ ;\n",
        "export INDEX_ROOT=experiments/notebook/indexes/cs224u.collection.2bits/ ;\n",
        "export INDEX_HOME=cs224u.collection.2bits ;\n",
        "export PORT=8888 ;\n",
        "python ColBERT/server.py\n",
        "```\n",
        "\n",
        "This will start the server and you should be all set.\n",
        "\n",
        "__Colab usage__: If you are working in a Colab _and you have a Pro account_, you can open a terminal from the lower left corner of the interface and then paste in the above code. If you don't have a Pro account, then it should work to uncomment the code in the following cell and run it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9d2542a5-610f-4e77-9f00-ec86b18e1d91",
      "metadata": {
        "id": "9d2542a5-610f-4e77-9f00-ec86b18e1d91",
        "outputId": "f99036df-2a94-4b9a-eb15-718208be12ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ColBERT'...\n",
            "remote: Enumerating objects: 2835, done.\u001b[K\n",
            "remote: Counting objects: 100% (1166/1166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (349/349), done.\u001b[K\n",
            "remote: Total 2835 (delta 948), reused 817 (delta 817), pack-reused 1669 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2835/2835), 2.07 MiB | 12.11 MiB/s, done.\n",
            "Resolving deltas: 100% (1785/1785), done.\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"INDEX_ROOT\"] = \"experiments/notebook/indexes/cs224u.collection.2bits/\"\n",
        "os.environ[\"INDEX_HOME\"] = \"cs224u.collection.2bits\"\n",
        "os.environ[\"PORT\"] = \"8888\"\n",
        "\n",
        "!git clone https://github.com/stanford-futuredata/ColBERT/\n",
        "\n",
        "!nohup python ColBERT/server.py &"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea56ea89-7055-401f-8afc-8e7687da284b",
      "metadata": {
        "id": "ea56ea89-7055-401f-8afc-8e7687da284b"
      },
      "source": [
        "This will take a minute to get started, and you won't get feedback on its progress, unfortunately. You can check that a server is running:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d07cae52-81d9-4ff4-9a3b-cf79cf2d74a6",
      "metadata": {
        "id": "d07cae52-81d9-4ff4-9a3b-cf79cf2d74a6",
        "outputId": "131afc77-46e1-4da0-9fe0-d262134f3530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root       21387 39.2  2.8 3368560 381824 ?      Rl   21:53   0:01 python3 ColBERT/server.py\n",
            "root       21404  0.0  0.0   6616  2300 ?        S    21:53   0:00 grep server.py\n"
          ]
        }
      ],
      "source": [
        "!ps aux | grep server.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5988243e-6985-4ccd-a40e-9a2475566ed3",
      "metadata": {
        "id": "5988243e-6985-4ccd-a40e-9a2475566ed3"
      },
      "source": [
        "You should see a mention of `ColBERT/server.py` in the output.\n",
        "\n",
        "Assuming the server is now running, we can connect to it:\n",
        "\n",
        "*Note*: if the ColBERT server is running on a separate server, you can update `127.0.0.1` with the server's IP address."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "556f268f-1a71-476d-bb13-8093feadaf6e",
      "metadata": {
        "id": "556f268f-1a71-476d-bb13-8093feadaf6e"
      },
      "outputs": [],
      "source": [
        "rm = dspy.ColBERTv2(url=\"http://127.0.0.1:8888/api/search\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d9bbc99-fcb2-4b22-b09b-c35371611709",
      "metadata": {
        "id": "0d9bbc99-fcb2-4b22-b09b-c35371611709"
      },
      "source": [
        "### DSPy set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "562fc500-bbab-48b7-a704-67c6d57bb09b",
      "metadata": {
        "id": "562fc500-bbab-48b7-a704-67c6d57bb09b"
      },
      "source": [
        "Here we establish the Language Model `lm` and Retriever Model `rm` that we will be using. The defaults for `lm` are just for development. You may want to develop using an inexpensive model and then do your final evalautions wih an expensive one. DSPy has support for a wide range of model APIs and local models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c118b014-e13f-433d-ad60-074636c7e738",
      "metadata": {
        "id": "c118b014-e13f-433d-ad60-074636c7e738"
      },
      "outputs": [],
      "source": [
        "lm = dspy.OpenAI(model='gpt-3.5-turbo', api_key=openai_key)\n",
        "\n",
        "dspy.settings.configure(lm=lm, rm=rm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "711785d7-6bb9-4041-92e6-cc5f9308477e",
      "metadata": {
        "id": "711785d7-6bb9-4041-92e6-cc5f9308477e"
      },
      "source": [
        "Here's a command you can run to see which OpenAI models are available; OpenAI has entered into an increasingly closed mode where many older models are not available, so there are likely to be some surprises lurking here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8a859fbb-e985-4031-b8ed-34f3b034db8d",
      "metadata": {
        "id": "8a859fbb-e985-4031-b8ed-34f3b034db8d"
      },
      "outputs": [],
      "source": [
        "# client = OpenAI(api_key = openai_key)\n",
        "# models = client.models.list()\n",
        "# print(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f0b3dc2-87d7-4b8b-b603-ee567e008710",
      "metadata": {
        "id": "0f0b3dc2-87d7-4b8b-b603-ee567e008710"
      },
      "source": [
        "## SQuAD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de295d35-fea5-46d2-9a01-022ad88e54cd",
      "metadata": {
        "id": "de295d35-fea5-46d2-9a01-022ad88e54cd"
      },
      "source": [
        "Our core development dataset is [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/). We chose this dataset because it is well-known and widely used, and it is large enough to support lots of meaningful development work, without, though, being so large as to require lots of compute power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5eaf2fd0-d060-4100-8702-f7311efd6129",
      "metadata": {
        "id": "5eaf2fd0-d060-4100-8702-f7311efd6129"
      },
      "outputs": [],
      "source": [
        "squad = load_dataset(\"squad\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36965402-e3da-4531-b7e9-4b12cebcdf30",
      "metadata": {
        "id": "36965402-e3da-4531-b7e9-4b12cebcdf30"
      },
      "source": [
        "The following utility just reads a SQuAD split in as a list of `dspy.Example` instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "21ad3e0b-7662-43b8-9409-a1a57442458b",
      "metadata": {
        "id": "21ad3e0b-7662-43b8-9409-a1a57442458b"
      },
      "outputs": [],
      "source": [
        "def get_squad_split(squad, split=\"validation\"):\n",
        "    \"\"\"\n",
        "    Use `split='train'` for the train split.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of dspy.Example with attributes question, answer\n",
        "\n",
        "    \"\"\"\n",
        "    data = zip(*[squad[split][field] for field in squad[split].features])\n",
        "    exs = [dspy.Example(question=q, answer=a['text'][0]).with_inputs(\"question\")\n",
        "           for eid, title, context, q, a in data]\n",
        "    return exs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3847d38-4e70-46b7-bf46-4c8b784c5ee5",
      "metadata": {
        "id": "a3847d38-4e70-46b7-bf46-4c8b784c5ee5"
      },
      "source": [
        "### SQuAD train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051c91e1-586b-4747-be39-3092e60f182f",
      "metadata": {
        "id": "051c91e1-586b-4747-be39-3092e60f182f"
      },
      "source": [
        "To build few-shot prompts, we will often sample SQuAD train examples, so we load that split here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "66c4feba-d580-4984-a449-0b92a53ef13a",
      "metadata": {
        "id": "66c4feba-d580-4984-a449-0b92a53ef13a"
      },
      "outputs": [],
      "source": [
        "squad_train = get_squad_split(squad, split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ab8c41-8eae-4d15-ad4d-e28b3c58eb4a",
      "metadata": {
        "id": "22ab8c41-8eae-4d15-ad4d-e28b3c58eb4a"
      },
      "source": [
        "### SQuAD dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "37198b33-c47b-4e0e-af8b-c00860658cc6",
      "metadata": {
        "id": "37198b33-c47b-4e0e-af8b-c00860658cc6"
      },
      "outputs": [],
      "source": [
        "squad_dev = get_squad_split(squad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c40c768-57cc-4a07-a3ef-5e34262b0ace",
      "metadata": {
        "id": "0c40c768-57cc-4a07-a3ef-5e34262b0ace"
      },
      "source": [
        "### SQuAD dev sample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "636601b5-c7ad-4177-a6d6-f3afdb0bedae",
      "metadata": {
        "id": "636601b5-c7ad-4177-a6d6-f3afdb0bedae"
      },
      "source": [
        "Evaluations are expensive in this new era! Here's a small sample to use for dev assessments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "64ccdd0e-de78-440d-bfbe-358c12eada5c",
      "metadata": {
        "tags": [],
        "id": "64ccdd0e-de78-440d-bfbe-358c12eada5c"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(1)\n",
        "\n",
        "dev_exs = random.sample(squad_dev, k=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28265d01-890d-4f04-b518-da0e8a1cb235",
      "metadata": {
        "id": "28265d01-890d-4f04-b518-da0e8a1cb235"
      },
      "source": [
        "## DSPy basics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101b9d12-fc8c-4aae-b09e-0d72a4aa54f5",
      "metadata": {
        "id": "101b9d12-fc8c-4aae-b09e-0d72a4aa54f5"
      },
      "source": [
        "### LM usage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c278daac-11f9-4327-a06f-1c408a06a71d",
      "metadata": {
        "id": "c278daac-11f9-4327-a06f-1c408a06a71d"
      },
      "source": [
        "Here's the most basic way to use the LM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "02364ed6-3c6d-4eaf-849a-2d9e30d84b53",
      "metadata": {
        "id": "02364ed6-3c6d-4eaf-849a-2d9e30d84b53",
        "outputId": "a59f884b-b924-4377-ee7f-4ec9eee15819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-78cef4fd1664>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is the birthplace of the first author to win a Hugo Award for a translation?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dsp/modules/gpt3.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, only_completed, return_sorted, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m#         kwargs = {**kwargs, \"logprobs\": 5}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/backoff/_sync.py\u001b[0m in \u001b[0;36mretry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mmax_tries_exceeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtries\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_tries_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dsp/modules/gpt3.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_choice_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dsp/modules/gpt3.py\u001b[0m in \u001b[0;36mbasic_request\u001b[0;34m(self, prompt, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"stringify_request\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dsp/modules/gpt3.py\u001b[0m in \u001b[0;36mchat_request\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cached_gpt3_turbo_request_v2_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mv1_cached_gpt3_turbo_request_v2_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dsp/modules/cache_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dsp/modules/gpt3.py\u001b[0m in \u001b[0;36mv1_cached_gpt3_turbo_request_v2_wrapped\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mNotebookCacheMemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mv1_cached_gpt3_turbo_request_v2_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mv1_cached_gpt3_turbo_request_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;31m# Return the output, without the metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshelving\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# Returns the output but not the metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshelving\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, call_id, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         return self._after_call(call_id, args, kwargs, shelving,\n\u001b[1;32m    773\u001b[0m                                 output, start_time)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dsp/modules/gpt3.py\u001b[0m in \u001b[0;36mv1_cached_gpt3_turbo_request_v2\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"stringify_request\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stringify_request\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mproxied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_proxied__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyProxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproxied\u001b[0m  \u001b[0;31m# pyright: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_proxy.py\u001b[0m in \u001b[0;36m__get_proxied__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_proxied__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__as_proxied__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_module_client.py\u001b[0m in \u001b[0;36m__load__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__load__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mresources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/__init__.py\u001b[0m in \u001b[0;36m_load_client\u001b[0;34m()\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         _client = _ModuleClient(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "lm(\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2356d9a8-750b-4383-bc5b-4173ca5c13ac",
      "metadata": {
        "id": "2356d9a8-750b-4383-bc5b-4173ca5c13ac"
      },
      "source": [
        "Keyword arguments to the underlying LM are passed through:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ab8deb-3b9d-4f57-bd70-7c170be294c5",
      "metadata": {
        "id": "19ab8deb-3b9d-4f57-bd70-7c170be294c5"
      },
      "outputs": [],
      "source": [
        "lm(\"Which U.S. states border no U.S. states?\", temperature=0.9, n=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c50e8d99-6d49-420d-ab5d-cc01b53cd4a1",
      "metadata": {
        "id": "c50e8d99-6d49-420d-ab5d-cc01b53cd4a1"
      },
      "source": [
        "With `lm.inspect_history`, we can see the most recent language model calls:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7cb5a5-3a3f-4e78-b9af-488fadc896ab",
      "metadata": {
        "id": "4f7cb5a5-3a3f-4e78-b9af-488fadc896ab"
      },
      "outputs": [],
      "source": [
        "_ = lm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a0f2df-df1f-422d-bff3-6c4a3d947f6e",
      "metadata": {
        "id": "d9a0f2df-df1f-422d-bff3-6c4a3d947f6e"
      },
      "source": [
        "### Signature-based prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0888a2a-fcaa-44b0-beef-b097c856c74b",
      "metadata": {
        "id": "a0888a2a-fcaa-44b0-beef-b097c856c74b"
      },
      "source": [
        "In DSPy, __signatures__ are declarative statements about what we want the model to do. In the following `\"question -> answer\"` is the signature (the most basic QA signature one could write), and `dspy.Predict` is used to turn this into a complete QA system:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f04cba-7d46-4680-a154-a0062243618e",
      "metadata": {
        "tags": [],
        "id": "11f04cba-7d46-4680-a154-a0062243618e"
      },
      "outputs": [],
      "source": [
        "basic_predictor = dspy.Predict(\"question -> answer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a994fc10-8c28-4836-bd7c-008a9a3d34e4",
      "metadata": {
        "id": "a994fc10-8c28-4836-bd7c-008a9a3d34e4"
      },
      "source": [
        "Here we use `basic_predictor`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe102d0-c0e5-45ad-aae8-51f6ea6e70f6",
      "metadata": {
        "tags": [],
        "id": "cfe102d0-c0e5-45ad-aae8-51f6ea6e70f6"
      },
      "outputs": [],
      "source": [
        "basic_predictor(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ad1a1b-d422-46df-8b03-4054bfec5fc1",
      "metadata": {
        "id": "97ad1a1b-d422-46df-8b03-4054bfec5fc1"
      },
      "source": [
        "And here is the prompt that was given to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af4f86db-97d5-4742-8468-4627de12f181",
      "metadata": {
        "tags": [],
        "id": "af4f86db-97d5-4742-8468-4627de12f181"
      },
      "outputs": [],
      "source": [
        "_ = lm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7845f62b-8af3-4fa2-af8d-f4ddd1181f30",
      "metadata": {
        "id": "7845f62b-8af3-4fa2-af8d-f4ddd1181f30"
      },
      "source": [
        "In many cases, we will want more control over the prompt. Writing a small custom `dspy.Signature` class is the easiest way to accomplish this. In the following, we just just tweak the initial instruction and provide some formatting guidance for the answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9dda770-e7ca-4682-b283-d4f4525adb68",
      "metadata": {
        "tags": [],
        "id": "d9dda770-e7ca-4682-b283-d4f4525adb68"
      },
      "outputs": [],
      "source": [
        "class BasicQASignature(dspy.Signature):\n",
        "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f7297a-b174-4566-8748-6b66d515ed25",
      "metadata": {
        "tags": [],
        "id": "83f7297a-b174-4566-8748-6b66d515ed25"
      },
      "outputs": [],
      "source": [
        "sig_predictor = dspy.Predict(BasicQASignature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a02d55-fac7-43c3-851b-3e21f06df14d",
      "metadata": {
        "tags": [],
        "id": "30a02d55-fac7-43c3-851b-3e21f06df14d"
      },
      "outputs": [],
      "source": [
        "sig_predictor(question=\"Which U.S. states border no U.S. states?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f613c05-ec78-4129-ac44-71bac4e253ad",
      "metadata": {
        "tags": [],
        "id": "2f613c05-ec78-4129-ac44-71bac4e253ad"
      },
      "outputs": [],
      "source": [
        "_ = lm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56169f83-0df6-46dc-b617-fadff1b96132",
      "metadata": {
        "id": "56169f83-0df6-46dc-b617-fadff1b96132"
      },
      "source": [
        "### Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e244aed0-403e-4707-a9eb-e29fc1e4dc57",
      "metadata": {
        "id": "e244aed0-403e-4707-a9eb-e29fc1e4dc57"
      },
      "source": [
        "One of the hallmarks of DSPy is that it adopts design patterns from PyTorch. The main example of this is DSPy's use of the `Module` as the basic unit for writing simple and complex programs. Here is a very basic module for QA that makes use of `BasicQASignature` as we defined it just above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506c9946-fee4-4dc3-a05e-767f85c25292",
      "metadata": {
        "tags": [],
        "id": "506c9946-fee4-4dc3-a05e-767f85c25292"
      },
      "outputs": [],
      "source": [
        "class BasicQA(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.generate_answer = dspy.Predict(BasicQASignature)\n",
        "\n",
        "    def forward(self, question):\n",
        "        return self.generate_answer(question=question)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c921aaed-6351-443d-8478-6e9a64b49d45",
      "metadata": {
        "id": "c921aaed-6351-443d-8478-6e9a64b49d45"
      },
      "source": [
        "As with PyTorch, the `forward` method is called when we want to make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67f65b7-0fea-40a3-ac78-795926025653",
      "metadata": {
        "tags": [],
        "id": "d67f65b7-0fea-40a3-ac78-795926025653"
      },
      "outputs": [],
      "source": [
        "basic_qa_model = BasicQA()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7044ec84-f76a-4af4-93f5-a82579237868",
      "metadata": {
        "tags": [],
        "id": "7044ec84-f76a-4af4-93f5-a82579237868"
      },
      "outputs": [],
      "source": [
        "basic_qa_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9961c89-914a-4736-8a01-1a3cd401821a",
      "metadata": {
        "tags": [],
        "id": "a9961c89-914a-4736-8a01-1a3cd401821a"
      },
      "source": [
        "The modular design of DSPy starts to become apparent now. If you want to change the above to use chain of thought instead of regular predictions, you need only change `dspy.Predict` to `dspy.ChainOfThought`, and similarly for `dspy.ReAct`, `dspy.ProgramOfThought`, or a module you wrote yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b9dac4-9495-448d-ad4b-38ab7260915b",
      "metadata": {
        "id": "17b9dac4-9495-448d-ad4b-38ab7260915b"
      },
      "source": [
        "### Optimizing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5200696-808f-4061-878c-26aa20701d58",
      "metadata": {
        "id": "f5200696-808f-4061-878c-26aa20701d58"
      },
      "source": [
        "The QA system we've defined so far is a zero-shot system. To change it into a few-shot system, we will rely on a DSPy optimizer (__teleprompter__). This will allow us to flexibly move between the zero-shot and few-shot formulations. The following code achieves this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdab9850-1d4d-4e04-b389-6ef55fd0b425",
      "metadata": {
        "tags": [],
        "id": "fdab9850-1d4d-4e04-b389-6ef55fd0b425"
      },
      "outputs": [],
      "source": [
        "from dspy.teleprompt import LabeledFewShot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72045705-2f27-46fe-b7bc-801a7d2e9ae4",
      "metadata": {
        "id": "72045705-2f27-46fe-b7bc-801a7d2e9ae4"
      },
      "source": [
        "Here we instantiate a `LabeledFewShot` teleprompter that will add three demonstrations. These will be sampled randomly from the set of train examples we provide:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befc8c18-fc64-4947-800d-6455dee90b68",
      "metadata": {
        "tags": [],
        "id": "befc8c18-fc64-4947-800d-6455dee90b68"
      },
      "outputs": [],
      "source": [
        "fewshot_teleprompter = LabeledFewShot(k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b512d9-ec54-49ca-ab7a-900dc2eea6cc",
      "metadata": {
        "id": "25b512d9-ec54-49ca-ab7a-900dc2eea6cc"
      },
      "source": [
        "And then we call `compile` on `basic_qa_model` as we defined it above. This returns a new module that we use like any other in DSPy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b327b603-2943-4bcc-b498-1fbafafefd0c",
      "metadata": {
        "tags": [],
        "id": "b327b603-2943-4bcc-b498-1fbafafefd0c"
      },
      "outputs": [],
      "source": [
        "basic_fewshot_qa_model = fewshot_teleprompter.compile(basic_qa_model, trainset=squad_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "921ec7f1-ed44-48a3-9c92-0e22911688f0",
      "metadata": {
        "tags": [],
        "id": "921ec7f1-ed44-48a3-9c92-0e22911688f0"
      },
      "outputs": [],
      "source": [
        "basic_fewshot_qa_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3180cdaa-dd34-4e0d-8455-e394bfde9fcc",
      "metadata": {
        "id": "3180cdaa-dd34-4e0d-8455-e394bfde9fcc"
      },
      "source": [
        "With `inspect_history`, we can see that prompts now contain demonstrations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9507fe6-1cc7-4c0a-8520-cc3812a07c27",
      "metadata": {
        "tags": [],
        "id": "f9507fe6-1cc7-4c0a-8520-cc3812a07c27"
      },
      "outputs": [],
      "source": [
        "_ = lm.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ba48440-4a65-41e8-b397-7b79f65fa0fe",
      "metadata": {
        "id": "6ba48440-4a65-41e8-b397-7b79f65fa0fe"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e8734a-49a1-4093-a2fb-09bb7d2f2859",
      "metadata": {
        "id": "27e8734a-49a1-4093-a2fb-09bb7d2f2859"
      },
      "source": [
        "Our evaluation metric is a standard one for SQuAD and related tasks: exact match of the answer (EM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f052a79f-ad9f-4f3e-a195-809567e2eea1",
      "metadata": {
        "tags": [],
        "id": "f052a79f-ad9f-4f3e-a195-809567e2eea1"
      },
      "outputs": [],
      "source": [
        "from dspy.evaluate import answer_exact_match\n",
        "from dspy.evaluate.evaluate import Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7341a846-5158-4acf-8aa5-aca61ef40174",
      "metadata": {
        "tags": [],
        "id": "7341a846-5158-4acf-8aa5-aca61ef40174"
      },
      "outputs": [],
      "source": [
        "answer_exact_match(dspy.Example(answer=\"STAGE 2!\"), dspy.Prediction(answer=\"stage 2\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f640e5bf-823f-4cdb-92da-a28f5cea7760",
      "metadata": {
        "id": "f640e5bf-823f-4cdb-92da-a28f5cea7760"
      },
      "source": [
        "In DSPy, `Evaluate` objects provide a uniform interface for running evaluations. Here are two for us to use in development. The first will evaluate on all of `dev_exs` and should provide a meaningful picture of how a system is doing. It could be expensive to use it a lot, though. The second is for debugging and is probably too small to give a reliable estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a3b58b-c114-4316-b8d7-2d8049132c1d",
      "metadata": {
        "tags": [],
        "id": "e6a3b58b-c114-4316-b8d7-2d8049132c1d"
      },
      "outputs": [],
      "source": [
        "dev_evaluater = Evaluate(\n",
        "    devset=dev_exs, # 200 examples\n",
        "    num_threads=1,\n",
        "    display_progress=True,\n",
        "    display_table=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72fd504e-4684-445d-b0cc-363cd1685b73",
      "metadata": {
        "tags": [],
        "id": "72fd504e-4684-445d-b0cc-363cd1685b73"
      },
      "outputs": [],
      "source": [
        "tiny_evaluater = Evaluate(\n",
        "    devset=dev_exs[: 15],\n",
        "    num_threads=1,\n",
        "    display_progress=True,\n",
        "    display_table=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d88a6c-55b6-4994-9413-1a2301c94903",
      "metadata": {
        "id": "47d88a6c-55b6-4994-9413-1a2301c94903"
      },
      "source": [
        "Here is a tiny (debugging-oriented) evaluation of our few-shot QA sytem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f736065-39f2-4d76-a258-e852767dbb8e",
      "metadata": {
        "tags": [],
        "id": "4f736065-39f2-4d76-a258-e852767dbb8e"
      },
      "outputs": [],
      "source": [
        "tiny_evaluater(basic_fewshot_qa_model, metric=answer_exact_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f1b41d-760c-4f28-8a2d-7f037b4f9d97",
      "metadata": {
        "id": "b3f1b41d-760c-4f28-8a2d-7f037b4f9d97"
      },
      "source": [
        "### Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51d4c8f4-a537-4d9b-9500-f881fceef1de",
      "metadata": {
        "id": "51d4c8f4-a537-4d9b-9500-f881fceef1de"
      },
      "source": [
        "The final major component of our systems is retrieval. When we defined `rm`, we connected to a remote ColBERT index and retriever system that we can now use for search."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5dfd114-96cf-468a-bac3-d3d39d6f3ca6",
      "metadata": {
        "id": "b5dfd114-96cf-468a-bac3-d3d39d6f3ca6"
      },
      "source": [
        "The basic `dspy.retrieve` method returns only passages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f4cafc-f5db-41c0-9561-ecde61331666",
      "metadata": {
        "tags": [],
        "id": "d8f4cafc-f5db-41c0-9561-ecde61331666"
      },
      "outputs": [],
      "source": [
        "retriever = dspy.Retrieve(k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891fc391-c177-4da7-9332-ab20cdba3c0d",
      "metadata": {
        "id": "891fc391-c177-4da7-9332-ab20cdba3c0d"
      },
      "outputs": [],
      "source": [
        "passages = retriever(\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdac37b-b5fe-421c-826f-4fd699cb2e36",
      "metadata": {
        "id": "abdac37b-b5fe-421c-826f-4fd699cb2e36"
      },
      "outputs": [],
      "source": [
        "passages.passages[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e1f577-408c-4ede-9e27-65a24aafca5f",
      "metadata": {
        "id": "a4e1f577-408c-4ede-9e27-65a24aafca5f"
      },
      "source": [
        "If we need passages with scores and other metadata, we can call `rm` directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f4ff3d-de41-4fc7-8943-6dfd894dd1f4",
      "metadata": {
        "id": "37f4ff3d-de41-4fc7-8943-6dfd894dd1f4"
      },
      "outputs": [],
      "source": [
        "rm(\"What is the birthplace of the first author to win a Hugo Award for a translation?\", k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2017ee-1375-4251-a24f-7f792852ffac",
      "metadata": {
        "id": "db2017ee-1375-4251-a24f-7f792852ffac"
      },
      "source": [
        "## Few-shot OpenQA with context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f05c0997-e624-4fc0-824d-e13066978b0a",
      "metadata": {
        "id": "f05c0997-e624-4fc0-824d-e13066978b0a"
      },
      "source": [
        "Let's build on the above core concepts to define a basic retrieval-augmented generation (RAG) program. This program solves the core task of few-shot OpenQA task and will serve as the basis for the homework questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1714dd71-02aa-4e84-840f-807b4e501732",
      "metadata": {
        "id": "1714dd71-02aa-4e84-840f-807b4e501732"
      },
      "source": [
        "We begin with a signature that takes context into account but is otherwise just like `BasicQASignature` above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd35bc4-9bbc-4286-ad6b-d7474b51423e",
      "metadata": {
        "tags": [],
        "id": "bcd35bc4-9bbc-4286-ad6b-d7474b51423e"
      },
      "outputs": [],
      "source": [
        "class ContextQASignature(dspy.Signature):\n",
        "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3de481d-d4dd-42c3-99c1-7a112c7f521f",
      "metadata": {
        "id": "f3de481d-d4dd-42c3-99c1-7a112c7f521f"
      },
      "source": [
        "And here is a complete program/system for the task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84481c9-6e6a-4331-a5e1-cf2b9e27b082",
      "metadata": {
        "tags": [],
        "id": "f84481c9-6e6a-4331-a5e1-cf2b9e27b082"
      },
      "outputs": [],
      "source": [
        "class RAG(dspy.Module):\n",
        "    def __init__(self, num_passages=1):\n",
        "        super().__init__()\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = self.retrieve(question).passages\n",
        "        prediction = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context, answer=prediction.answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c4c1ddd-455e-4ad5-b1b1-bf1267364660",
      "metadata": {
        "tags": [],
        "id": "7c4c1ddd-455e-4ad5-b1b1-bf1267364660"
      },
      "outputs": [],
      "source": [
        "rag_model = RAG(num_passages=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fce28fa-aa8a-4cec-a07a-5365a5eb32df",
      "metadata": {
        "tags": [],
        "id": "7fce28fa-aa8a-4cec-a07a-5365a5eb32df"
      },
      "outputs": [],
      "source": [
        "rag_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "873286e4-aaa7-4359-a5f2-04f8cbcceac8",
      "metadata": {
        "id": "873286e4-aaa7-4359-a5f2-04f8cbcceac8"
      },
      "source": [
        "An optional tiny evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25715550-2ba8-44bb-9a11-ca3bc3e0af56",
      "metadata": {
        "tags": [],
        "id": "25715550-2ba8-44bb-9a11-ca3bc3e0af56"
      },
      "outputs": [],
      "source": [
        "tiny_evaluater(rag_model, metric=answer_exact_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeb28556-d901-4b6b-8a7d-93040203294d",
      "metadata": {
        "id": "eeb28556-d901-4b6b-8a7d-93040203294d"
      },
      "source": [
        "## Question 1: Optimizing RAG [2 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f481081-3e16-4ccd-b379-c7e0c3011286",
      "metadata": {
        "id": "1f481081-3e16-4ccd-b379-c7e0c3011286"
      },
      "source": [
        "We used `RAG` above as a zero-shot system. We could turn it into a few-shot system by using `LabeledFewShot` as we did in [the teleprompting section](#Teleprompting) above, but this may actually be problematic: if we randomly sample demonstrations with retrieved passages, we might be instructing the model with a lot of cases where the context passage isn't helping (and may actually be actively misleading the model).\n",
        "\n",
        "What we'd like to do is select demonstrations where the model gets the answer correct and the context passage does contain the answer. To do this, we will use the DSPy `BootstrapFewShot` optimizer. There are two steps for this: (1) defining a metric and (2) running the optimizer.\n",
        "\n",
        "__Note__: The code for this question can be found in the DSPy tutorials, and you should feel free to make use of that code. The goal is to help you understand the design patterns and overall logic of optimizing DSPy programs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff0ae027-f51a-4607-822f-2a721acde73c",
      "metadata": {
        "id": "ff0ae027-f51a-4607-822f-2a721acde73c"
      },
      "source": [
        "__Task 1__: Complete `validate_context_and_answer` according to the specification in the docstring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad09f428-1a68-4cef-9e7a-7c6faf9244a4",
      "metadata": {
        "tags": [],
        "id": "ad09f428-1a68-4cef-9e7a-7c6faf9244a4"
      },
      "outputs": [],
      "source": [
        "def validate_context_and_answer(example, pred, trace=None):\n",
        "    \"\"\"Return True if `example.answer` matches `pred.answer` according\n",
        "    to `dspy.evaluate.answer_exact_match` and `pred.context` contains\n",
        "    `example.answer` according to `dspy.evaluate.answer_passage_match`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    example: dspy.Example\n",
        "        with attributes `answer` and `context`\n",
        "    pred: dspy.Example\n",
        "        with attributes `answer` and `context`\n",
        "    trace : None (included for dspy internal compatibility)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0918c5f-2864-4856-adcf-ccb94aca6108",
      "metadata": {
        "id": "c0918c5f-2864-4856-adcf-ccb94aca6108"
      },
      "source": [
        "A test you can use to check your implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddbca59c-7c11-4e4b-bec3-18a2ecde563b",
      "metadata": {
        "tags": [],
        "id": "ddbca59c-7c11-4e4b-bec3-18a2ecde563b"
      },
      "outputs": [],
      "source": [
        "def test_validate_context_and_answer(func):\n",
        "    examples = [\n",
        "        (\n",
        "            dspy.Example(question=\"Q1\", answer=\"B\"),\n",
        "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"B\"),\n",
        "            True\n",
        "        ),\n",
        "        # Context doesn't contain answer, but predicted answer is correct.\n",
        "        (\n",
        "            dspy.Example(question=\"Q1\", answer=\"D\"),\n",
        "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"D\"),\n",
        "            False\n",
        "        ),\n",
        "        # Context contains answer, but predicted answer is not correct.\n",
        "        (\n",
        "            dspy.Example(question=\"Q1\", answer=\"C\"),\n",
        "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"D\"),\n",
        "            False\n",
        "        )\n",
        "    ]\n",
        "    errcount = 0\n",
        "    for ex, pred, result in examples:\n",
        "        predicted = func(ex, pred, trace=None)\n",
        "        if predicted != result:\n",
        "            errcount += 1\n",
        "            print(f\"Error for `{func.__name__}`: \"\n",
        "                  f\"Expected inputs\\n\\t{ex}\\n\\t{pred} to return {result}.\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors detected for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38aa3141-ae8f-4bc6-a26e-64d108537612",
      "metadata": {
        "tags": [],
        "id": "38aa3141-ae8f-4bc6-a26e-64d108537612"
      },
      "outputs": [],
      "source": [
        "test_validate_context_and_answer(validate_context_and_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f091ca79-ccbe-4429-bfe7-c4f1de118adf",
      "metadata": {
        "tags": [],
        "id": "f091ca79-ccbe-4429-bfe7-c4f1de118adf"
      },
      "source": [
        "__Task 2__: Complete `bootstrap_optimize` according to the specification in the docstring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129e7e92-033e-4f38-b309-94dac2b66d87",
      "metadata": {
        "tags": [],
        "id": "129e7e92-033e-4f38-b309-94dac2b66d87"
      },
      "outputs": [],
      "source": [
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "def bootstrap_optimize(model):\n",
        "    \"\"\"Use `BootstrapFewShot` to optimize `model`, with the metric set\n",
        "    to `validate_context_and_answer` as defined above and default\n",
        "    values for all other keyword arguments to `BootstrapFewShot`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: dspy.Module\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dspy.Module, the optimized version of `model`\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f26af22-6d7d-4456-9e30-8f80f5b0b401",
      "metadata": {
        "id": "4f26af22-6d7d-4456-9e30-8f80f5b0b401"
      },
      "source": [
        "A test you can use to check your implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30dd9f56-31cc-4e45-8bc2-0fe56c3806a7",
      "metadata": {
        "tags": [],
        "id": "30dd9f56-31cc-4e45-8bc2-0fe56c3806a7"
      },
      "outputs": [],
      "source": [
        "def test_bootstrap_optimize(func):\n",
        "    model = RAG()\n",
        "    compiled = func(model)\n",
        "    if not hasattr(compiled, \"_compiled\") or not compiled._compiled:\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "               \"The return value is not a compiled program.\")\n",
        "        return None\n",
        "    state = compiled.dump_state()\n",
        "    if not state['generate_answer']['demos']:\n",
        "        print(f\"Error for `{func.__name__}`: \"\n",
        "               \"The compiled program has no `demos`.\")\n",
        "        return None\n",
        "    print(f\"No errors detected for `{func.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "733c1c31-9c68-4d2a-a1c3-4eed0e1caa6f",
      "metadata": {
        "tags": [],
        "id": "733c1c31-9c68-4d2a-a1c3-4eed0e1caa6f"
      },
      "outputs": [],
      "source": [
        "test_bootstrap_optimize(bootstrap_optimize)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9971ffd0-a563-4d56-a896-0735a63ae92f",
      "metadata": {
        "tags": [],
        "id": "9971ffd0-a563-4d56-a896-0735a63ae92f"
      },
      "source": [
        "## Question 2: Multi-passage summarization [2 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527e4d85-05d7-4bc2-beaf-2434d4fe41da",
      "metadata": {
        "id": "527e4d85-05d7-4bc2-beaf-2434d4fe41da"
      },
      "source": [
        "The `dspy.Retrieve` layer in our `RAG` retrieves `k` passages, where `k` is under the control of the user. One hypothesis one might have is that it would be good to summarize these passages before using them as evidence. This seems especially likely to help in scenarios where the question can be answered only by synthesizing information across documents – it might be too much to ask the language model to do both synthesizing and answering in a single step.\n",
        "\n",
        "The current question maps out a basic strategy for summarization. The heart of it is a new signature called `SummarizeSignature`. This can be used on its own with a simple `dspy.Predict` call, and we'll incorporate it into a RAG program in the next question.\n",
        "\n",
        "For this question, though, your task is just to complete `SummarizeSignature`. The requirements are as follows:\n",
        "\n",
        "1. A `__doc__` value that gives an instruction that seems to work well. You can decide what to say here.\n",
        "2. A `dspy.InputField` named `context`. You can decide whether to use the `desc` parameter.\n",
        "3. A `dspy.OutputField` named `summary`. You can decide whether to use the `desc` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c080a6-d2e1-4d7a-ac60-5ef3a6931ad1",
      "metadata": {
        "tags": [],
        "id": "b7c080a6-d2e1-4d7a-ac60-5ef3a6931ad1"
      },
      "outputs": [],
      "source": [
        "class SummarizeSignature(dspy.Signature):\n",
        "    pass\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6091f20-1cae-4e04-bd50-929271ae6a18",
      "metadata": {
        "id": "a6091f20-1cae-4e04-bd50-929271ae6a18"
      },
      "source": [
        "Here's a simple test that just checks for the required pieces in a basic way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428c971a-2dcd-4344-afa0-8e52938ca4ee",
      "metadata": {
        "tags": [],
        "id": "428c971a-2dcd-4344-afa0-8e52938ca4ee"
      },
      "outputs": [],
      "source": [
        "def test_SummarizeSignature(sigclass):\n",
        "    fields = sigclass.fields\n",
        "    expected_fieldnames = ['context', 'summary']\n",
        "    fieldnames = sorted(fields)\n",
        "    errcount = 0\n",
        "    if expected_fieldnames != fieldnames:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{sigclass.__name__}`: \"\n",
        "              f\"Expected fieldnames {expected_fieldnames}, got {fieldnames}.\")\n",
        "    if not sigclass.__doc__:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{sigclass.__name__}`: No docstring specified.\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors detected for `{sigclass.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec39e4d-b3ca-4355-9695-c9f61a24f3d2",
      "metadata": {
        "tags": [],
        "id": "fec39e4d-b3ca-4355-9695-c9f61a24f3d2"
      },
      "outputs": [],
      "source": [
        "test_SummarizeSignature(SummarizeSignature)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "881ee5d0-2bd6-4cb0-873c-21f963a78555",
      "metadata": {
        "id": "881ee5d0-2bd6-4cb0-873c-21f963a78555"
      },
      "source": [
        "Here is the simplest way to use `SummarizeSignature`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8129a3-90fb-4810-b18b-84e75525dd16",
      "metadata": {
        "tags": [],
        "id": "5e8129a3-90fb-4810-b18b-84e75525dd16"
      },
      "outputs": [],
      "source": [
        "summarizer = dspy.Predict(SummarizeSignature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8bfdb34-07d8-4488-a1ed-1b4788a2a119",
      "metadata": {
        "tags": [],
        "id": "d8bfdb34-07d8-4488-a1ed-1b4788a2a119"
      },
      "outputs": [],
      "source": [
        "summarizer(context=retriever(\"Where is Guarani spoken?\").passages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b7a44f-c50d-4674-9fbb-fcf216222e3a",
      "metadata": {
        "id": "24b7a44f-c50d-4674-9fbb-fcf216222e3a"
      },
      "source": [
        "## Question 3: Summarizing RAG [2 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c812e189-2778-442f-81b1-577c303445a8",
      "metadata": {
        "id": "c812e189-2778-442f-81b1-577c303445a8"
      },
      "source": [
        "Your task for this question is to modify `RAG` as defined above so that the retrieved passages are summarized before being passed to `generate_answer`.\n",
        "\n",
        "Here is the `RAG` system copied from above with the class name changed to the one we will use for this new system. Your task is to add the summarization step. This should be very straightforward given the modular design that DSPy supports and encourages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa956847-d6ff-40cf-bf02-9043863e548e",
      "metadata": {
        "tags": [],
        "id": "fa956847-d6ff-40cf-bf02-9043863e548e"
      },
      "outputs": [],
      "source": [
        "class SummarizingRAG(dspy.Module):\n",
        "    def __init__(self, num_passages=3):\n",
        "        # Please name your summarization later `summarize` so that we\n",
        "        # can check for its presence.\n",
        "        super().__init__()\n",
        "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
        "        ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = self.retrieve(question).passages\n",
        "        ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "        prediction = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context, answer=prediction.answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16b65d8-14ca-4dbe-a815-a0d00940b0b4",
      "metadata": {
        "id": "f16b65d8-14ca-4dbe-a815-a0d00940b0b4"
      },
      "source": [
        "A simple test for this design spec:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "824f063d-1735-4bf3-9337-e9728a5b7800",
      "metadata": {
        "tags": [],
        "id": "824f063d-1735-4bf3-9337-e9728a5b7800"
      },
      "outputs": [],
      "source": [
        "def test_SummarizingRAG(classname):\n",
        "    model = classname(num_passages=3)\n",
        "    errcount = 0\n",
        "    if not hasattr(model, \"summarize\"):\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{classname.__name__}`: \"\n",
        "              f\"Expected a layer called 'summarize'\")\n",
        "    context = model.retrieve(\"What are some foods?\").passages\n",
        "    pred = model(\"What are some foods?\")\n",
        "    if context == pred.context:\n",
        "        errcount += 1\n",
        "        print(f\"Error for `{classname.__name__}`: \"\n",
        "              \"The model seems to be using raw retrieved contexts \"\n",
        "              \"for predictions rather than summarizing them.\")\n",
        "    if errcount == 0:\n",
        "        print(f\"No errors detected for `{classname.__name__}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e1d38c4-540c-4473-b464-0061b5b8a09c",
      "metadata": {
        "tags": [],
        "id": "8e1d38c4-540c-4473-b464-0061b5b8a09c"
      },
      "outputs": [],
      "source": [
        "test_SummarizingRAG(SummarizingRAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9e3b6ad-b960-4b8f-8137-a9b90953b2fc",
      "metadata": {
        "id": "f9e3b6ad-b960-4b8f-8137-a9b90953b2fc"
      },
      "source": [
        "Model usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95e03778-5a7f-4119-ac62-f4965bfe9a8c",
      "metadata": {
        "tags": [],
        "id": "95e03778-5a7f-4119-ac62-f4965bfe9a8c"
      },
      "outputs": [],
      "source": [
        "summarizing_rag_model = SummarizingRAG()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5077370b-156f-4738-948b-86d832b2ebbd",
      "metadata": {
        "tags": [],
        "id": "5077370b-156f-4738-948b-86d832b2ebbd"
      },
      "outputs": [],
      "source": [
        "summarizing_rag_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ebc3e9-7baf-4e1c-81a0-8c1e3588a882",
      "metadata": {
        "id": "49ebc3e9-7baf-4e1c-81a0-8c1e3588a882"
      },
      "source": [
        "Note: if you decide to use `BootstrapFewShot` on this, be sure not to use the metric we defined above, which requires that the passage embeds the correct answer as a substring. Now that we are summarizing, this is unlikely to hold, even if the answers are good ones."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19655d70-007c-4a41-9f3b-e20df9c5169b",
      "metadata": {
        "id": "19655d70-007c-4a41-9f3b-e20df9c5169b"
      },
      "source": [
        "## Question 4: Your original system [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d8d268f-70e1-4325-a2ff-7361d73788b9",
      "metadata": {
        "id": "2d8d268f-70e1-4325-a2ff-7361d73788b9"
      },
      "source": [
        "This question asks you to design your own few-shot OpenQA system. All of the code above can be used and modified for this, and the requirement is just that you try something new that goes beyond what we've done so far.\n",
        "\n",
        "Terms for the bake-off:\n",
        "\n",
        "* You can make free use of SQuAD and other publicly available data.\n",
        "\n",
        "* The LM must be an autoregressive language model. No trained QA components can be used. This includes general purpose LMs that have been fine-tuned for QA. (We have obviously waded into some vague territory here. The spirit of this is to make use of frozen, general-purpose models. We welcome questions about exactly how this is defined, since it could be instructive to explore this.)\n",
        "\n",
        "Here are some ideas for the original system:\n",
        "\n",
        "* We have relied almost entirely on `dspy.Predict`. Drop-in replacements include `dspy.ChainOfThought` and `dspy.ReAct`.\n",
        "\n",
        "* We have used only one retriever. DSPy supports other retrieval mechanisms, including retrieval using [You.com](https://you.com/).\n",
        "\n",
        "* DSPy includes additional optimizers. Two that are worth trying are `SignatureOptimizer` for automatic prompt exploration and `BootstrapFewShotWithRandomSearch`, which combines `LabeledFewShot` and `BootstrapFewShot`,\n",
        "\n",
        "* Our one-step summarization procedure from Question 3 doesn't change the query to the retriever. We might want it to change as we gather evidence. This is a common design principle for multi-hop OpenQA systems.\n",
        "\n",
        "__Original system instructions__:\n",
        "\n",
        "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b557f3c3-ee72-480e-9d99-9095372f99c4",
      "metadata": {
        "id": "b557f3c3-ee72-480e-9d99-9095372f99c4"
      },
      "outputs": [],
      "source": [
        "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
        "#   1) Textual description of your system.\n",
        "#   2) The code for your original system.\n",
        "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
        "\n",
        "# START COMMENT: Enter your system description in this cell.\n",
        "\n",
        "def foo(s):\n",
        "    return True\n",
        "\n",
        "# STOP COMMENT: Please do not remove this comment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b39c60-7494-46a6-b450-42b7e9fe3aad",
      "metadata": {
        "id": "c5b39c60-7494-46a6-b450-42b7e9fe3aad"
      },
      "source": [
        "## Question 5: Bakeoff entry [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff871c1-cc38-4e2f-af38-45b3619e8329",
      "metadata": {
        "id": "cff871c1-cc38-4e2f-af38-45b3619e8329"
      },
      "source": [
        "For the bake-off, you simply need to be able to run your system on the file\n",
        "\n",
        "```data/openqa/cs224u-openqa-test-unlabeled.txt```\n",
        "\n",
        "The following code should download it for you if necessary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca87f81-556b-46eb-904f-a3df70fdacb5",
      "metadata": {
        "id": "4ca87f81-556b-46eb-904f-a3df70fdacb5"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "\n",
        "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")):\n",
        "    os.makedirs(os.path.join('data', 'openqa'), exist_ok=True)\n",
        "    wget.download('https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt', out='data/openqa/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d0024b-9af7-4e3b-930e-1e7603d4d85c",
      "metadata": {
        "id": "68d0024b-9af7-4e3b-930e-1e7603d4d85c"
      },
      "source": [
        "If the above fails, you can just download https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt and place it in `data/openqa`.\n",
        "\n",
        "This file contains only questions. The starter code below will help you structure this. It writes a file \"cs224u-openqa-bakeoff-entry.json\" to the current directory. That file should be uploaded as-is. Please do not change its name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403b0000-5bc0-4657-91e4-5a6e87f2f899",
      "metadata": {
        "tags": [],
        "id": "403b0000-5bc0-4657-91e4-5a6e87f2f899"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tqdm\n",
        "\n",
        "def create_bakeoff_submission(model):\n",
        "    \"\"\"\"\n",
        "    The argument `model` is a `dspy.Module`. The return value of its\n",
        "    `forward` method must have an `answer` attribute.\n",
        "    \"\"\"\n",
        "\n",
        "    filename = os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")\n",
        "\n",
        "    # This should become a mapping from questions (str) to response\n",
        "    # dicts from your system.\n",
        "    gens = {}\n",
        "\n",
        "    with open(filename) as f:\n",
        "        questions = f.read().splitlines()\n",
        "\n",
        "    # Here we loop over the questions, run the system `model`, and\n",
        "    # store its `answer` value as the prediction:\n",
        "    for question in tqdm.tqdm(questions):\n",
        "        gens[question] = model(question=question).answer\n",
        "\n",
        "    # Quick tests we advise you to run:\n",
        "    # 1. Make sure `gens` is a dict with the questions as the keys:\n",
        "    assert all(question in gens for q in questions)\n",
        "    # 2. Make sure the values are str:\n",
        "    assert all(isinstance(d, str) for d in gens.values())\n",
        "\n",
        "    # And finally the output file:\n",
        "    with open(\"cs224u-openqa-bakeoff-entry.json\", \"wt\") as f:\n",
        "        json.dump(gens, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc0f32a8-547e-4a2c-8283-44adf69657ed",
      "metadata": {
        "id": "cc0f32a8-547e-4a2c-8283-44adf69657ed"
      },
      "source": [
        "Here's what it looks like to evaluate our first program, `basic_qa_model`, on the bakeoff data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce20e9ae-bb82-4dff-896f-aad7f150177d",
      "metadata": {
        "tags": [],
        "id": "ce20e9ae-bb82-4dff-896f-aad7f150177d"
      },
      "outputs": [],
      "source": [
        "create_bakeoff_submission(basic_qa_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}